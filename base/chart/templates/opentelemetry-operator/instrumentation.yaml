{{- /*
Instrumentation CR for Elastic APM via OpenTelemetry Operator

This resource is managed separately since the CRD is created by the OpenTelemetry Operator.
The Instrumentation CR will be applied by Flux after the operator's HelmRelease is ready.

We use a dedicated ConfigMap and a post-install Job to apply the Instrumentation CR
after the operator CRDs are available.
*/ -}}
{{- if and .Values.opentelemetryOperator.enabled .Values.opentelemetryOperator.instrumentation.enabled }}
{{- $apmSecretToken := .Values.opentelemetryOperator.instrumentation.elasticApm.secretToken }}
{{- $apmServerUrl := .Values.opentelemetryOperator.instrumentation.elasticApm.serverUrl }}
---
# ConfigMap containing the Instrumentation CR manifest
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-otel-instrumentation-manifest
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: opentelemetry-operator
    app.kubernetes.io/component: "instrumentation"
    {{- include "commonLabels" . | nindent 4 }}
data:
  instrumentation.yaml: |
    apiVersion: opentelemetry.io/v1alpha1
    kind: Instrumentation
    metadata:
      name: elastic-apm
      namespace: opentelemetry-operator-system
      labels:
        app.kubernetes.io/name: opentelemetry-operator
        app.kubernetes.io/component: instrumentation
    spec:
      exporter:
        endpoint: {{ $apmServerUrl | default "http://apm-server.elastic-stack.svc:8200" }}
      propagators:
        - tracecontext
        - baggage
        - b3
      resource:
        addK8sUIDAttributes: true
      env:
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: {{ $apmServerUrl | default "http://apm-server.elastic-stack.svc:8200" }}
        - name: OTEL_EXPORTER_OTLP_PROTOCOL
          value: grpc
        - name: OTEL_METRICS_EXPORTER
          value: otlp
        - name: OTEL_LOGS_EXPORTER
          value: otlp
        {{- if $apmSecretToken }}
        - name: OTEL_EXPORTER_OTLP_HEADERS
          value: "Authorization=Bearer {{ $apmSecretToken }}"
        {{- end }}
      java:
        image: docker.elastic.co/observability/elastic-otel-javaagent:1.0.0
        env:
          - name: OTEL_JAVAAGENT_DEBUG
            value: "false"
          - name: OTEL_INSTRUMENTATION_MICROMETER_ENABLED
            value: "true"
      nodejs:
        image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-nodejs:0.49.1
        env:
          - name: OTEL_NODE_DEBUG
            value: "false"
      python:
        image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-python:0.44b0
        env:
          - name: OTEL_PYTHON_LOG_LEVEL
            value: info
      dotnet:
        image: ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-dotnet:1.2.0
        env:
          - name: OTEL_DOTNET_AUTO_DEBUG
            value: "false"
      go:
        image: ghcr.io/open-telemetry/opentelemetry-go-instrumentation/autoinstrumentation-go:v0.14.0-alpha
---
# ServiceAccount for the Instrumentation installer job
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-otel-instrumentation-installer
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: opentelemetry-operator
    app.kubernetes.io/component: "instrumentation-installer"
    {{- include "commonLabels" . | nindent 4 }}
---
# ClusterRole for applying Instrumentation CRs
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ .Release.Name }}-otel-instrumentation-installer
  labels:
    app.kubernetes.io/name: opentelemetry-operator
    app.kubernetes.io/component: "instrumentation-installer"
    {{- include "commonLabels" . | nindent 4 }}
rules:
  - apiGroups: ["opentelemetry.io"]
    resources: ["instrumentations"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["apiextensions.k8s.io"]
    resources: ["customresourcedefinitions"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "list", "watch"]
---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{ .Release.Name }}-otel-instrumentation-installer
  labels:
    app.kubernetes.io/name: opentelemetry-operator
    app.kubernetes.io/component: "instrumentation-installer"
    {{- include "commonLabels" . | nindent 4 }}
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: {{ .Release.Name }}-otel-instrumentation-installer
subjects:
  - kind: ServiceAccount
    name: {{ .Release.Name }}-otel-instrumentation-installer
    namespace: {{ .Release.Namespace }}
---
# Job to apply the Instrumentation CR after operator is ready
# This job waits for the CRD and then applies the Instrumentation manifest
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-otel-instrumentation-installer
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/name: opentelemetry-operator
    app.kubernetes.io/component: "instrumentation-installer"
    {{- include "commonLabels" . | nindent 4 }}
  annotations:
    # Run after Helm install/upgrade
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-weight": "10"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 30
  activeDeadlineSeconds: 600
  template:
    metadata:
      labels:
        app.kubernetes.io/name: opentelemetry-operator
        app.kubernetes.io/component: "instrumentation-installer"
    spec:
      serviceAccountName: {{ .Release.Name }}-otel-instrumentation-installer
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: installer
          image: bitnami/kubectl:latest
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for Instrumentation CRD to be available..."
              until kubectl get crd instrumentations.opentelemetry.io >/dev/null 2>&1; do
                echo "CRD not found, waiting..."
                sleep 10
              done
              echo "CRD found! Waiting for operator to be ready..."
              kubectl wait --for=condition=available deployment -l app.kubernetes.io/name=opentelemetry-operator -n opentelemetry-operator-system --timeout=300s || true
              echo "Applying Instrumentation CR..."
              kubectl apply -f /config/instrumentation.yaml
              echo "Instrumentation CR applied successfully!"
          volumeMounts:
            - name: config
              mountPath: /config
      volumes:
        - name: config
          configMap:
            name: {{ .Release.Name }}-otel-instrumentation-manifest
{{- end }}
